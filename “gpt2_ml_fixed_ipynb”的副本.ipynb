{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnzhaoxiao/NLP/blob/master/%E2%80%9Cgpt2_ml_fixed_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "14G5pfZbLCya",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUKPJPlo8jM3",
        "outputId": "3a6ca734-0001-4a86-c844-31a2b4802d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions for running/使用说明:\n",
        "## First time opration (run first time) / 初次使用(只需第一次运行时遵循)\n",
        "### 1. mount your Gdrive / 挂载你的Gdrive\n",
        "Run cell 1 to mount your Gdrive. / 运行第一个单元，挂载你的Gdrive\n",
        "### 2. Download necessery files. / 下载必要的文件\n",
        "Run cell 2 to download necessary files. / 运行第二个单元，下载必要的文件\n",
        "### 3. Install tesorflow / 安装tensorflow\n",
        "Run cell 3 / 运行第三个cell，安装tensorflow\n",
        "### 4. Run! / 运行！\n",
        "Set your config in cell 4 and run it / 设置你的config，运行第四个单元\n",
        "## Common usage (run every time) / 常用使用（每次运行都要遵循）\n",
        "### 1. Install tesorflow / 安装tensorflow\n",
        "Run cell 3 / 运行第三个cell，安装tensorflow\n",
        "### 4. Run! / 运行！\n",
        "Set your config in cell 4 and run it / 设置你的config，运行第四个单元\n"
      ],
      "metadata": {
        "id": "wTJz_uQtKUbi",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agzDsynLHABe",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "edac57b2-57f3-4693-caa1-41c142f5db77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "########## Cell 1 ##########\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir /content/drive/MyDrive/gptroot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########## Cell 2 ##########\n",
        "!git clone -q https://github.com/zxkmm/gpt2-ml-fixed /content/drive/MyDrive/gptroot/gpt2-ml\n",
        "%cd /content/drive/MyDrive/gptroot/gpt2-ml\n",
        "!mkdir -p /content/drive/MyDrive/gptroot/gpt2-ml/models/mega\n",
        "!gdown 1XDHAtKLLYAxnl2jYu4JaqCJ9VglCAB30 -O models/mega/model.ckpt-220000.data-00000-of-00001\n",
        "!wget -q --show-progress https://github.com/zxkmm/gpt2-ml-fixed/releases/download/v1.0/model.ckpt-220000.index -P models/mega\n",
        "!wget -q --show-progress https://github.com/zxkmm/gpt2-ml-fixed/releases/download/v1.0/model.ckpt-220000.meta -P models/mega\n",
        "!echo 'Download finished.🍺'\n",
        "# If gdown.pl failed, please uncomment following code & exec\n",
        "# !python scripts/down_gdrive_file.py -file_id='1XDHAtKLLYAxnl2jYu4JaqCJ9VglCAB30' -file_path='models/mega/model.ckpt-220000.data-00000-of-00001'"
      ],
      "metadata": {
        "id": "gIHKwaBULnXD",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "26e14ccb-d5bf-419e-bb29-4610f0d9b82d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/gptroot/gpt2-ml\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XDHAtKLLYAxnl2jYu4JaqCJ9VglCAB30\n",
            "To: /content/drive/MyDrive/gptroot/gpt2-ml/models/mega/model.ckpt-220000.data-00000-of-00001\n",
            "100% 5.50G/5.50G [03:55<00:00, 23.4MB/s]\n",
            "model.ckpt-220000.m 100%[===================>]  41.99M  56.3MB/s    in 0.7s    \n",
            "Download finished.🍺\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q --show-progress https://github.com/zxkmm/gpt2-ml-fixed/releases/download/v1.0/model.ckpt-220000.index -P models/mega"
      ],
      "metadata": {
        "id": "PB_oz_7ftM8l",
        "outputId": "284f323f-aad9-4ca2-deb9-059589ff8b61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rmodel.ckpt-220000.i   0%[                    ]       0  --.-KB/s               \rmodel.ckpt-220000.i 100%[===================>]  25.56K  --.-KB/s    in 0.002s  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########## Cell 3 ##########\n",
        "!pip install -r requirements-gpu.txt &> tmp.log"
      ],
      "metadata": {
        "id": "da0E3aOMLuNZ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## Cell 4 ##########\n",
        "#@title #Inference\n",
        "%cd /content/drive/MyDrive/gptroot/gpt2-ml\n",
        "min_len = 150#@param {type:\"number\", min:5, max:1024, step:1}\n",
        "sp_num = 2#@param {type:\"number\", min:1, max:50, step:1}\n",
        "!PYTHONPATH=$(pwd) python scripts/demo.py -ckpt_fn models/mega/model.ckpt-220000 -min_len $min_len -samples $sp_num"
      ],
      "metadata": {
        "id": "yhDIsr-hOwqm",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "935ea0fb-c28c-4bca-aa6a-5b74fedbef93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/gptroot/gpt2-ml\n",
            "INFO:tensorflow:Restoring parameters from models/mega/model.ckpt-220000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "9J3tSql9ugx3",
        "outputId": "b8de8399-b3d2-4a2d-cf48-ab761445e568",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}